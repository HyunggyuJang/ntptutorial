{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural next-step prediction | part 2: learning\n",
    "Tutorial on neural theorem proving\\\n",
    "Author: Sean Welleck\n",
    "\n",
    "----------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### High-level goal\n",
    "\n",
    "Our goal is to train a neural next-step predictor $p_\\theta(y_t|x_t)$ on the dataset that we collected in the previous notebook.\n",
    "\n",
    "To do so, we will fine-tune a pretrained language model on the dataset $\\mathcal{D}=\\{(x_t,y_t)\\}$ using the standard supervised fine-tuning approach:\n",
    "\n",
    "$$\n",
    "\\min_\\theta \\sum_{(x_t,y_t)\\in \\mathcal{D}}-\\log p_\\theta(y_t|x_t).\n",
    "$$\n",
    "\n",
    "That is, we maximize the conditional likelihood of a next-step $y_t$ given the context $x_t$. \\\n",
    "This corresponds to minimizing a cross-entropy loss at each position of the next-step, $\\sum_{\\ell=1}^{{|y_t|}}-\\log p_\\theta(y_t^\\ell|y_t^{<\\ell})$.\n",
    "\n",
    "This is because that we can think $x_t$ as the state after applying $y_t^{<\\ell}$ to $x_1$. So, the former formulation also includes the later formulation, with one additional info, the initial state, $x_1$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "The implementation consists of two steps:\n",
    "\n",
    "1. **Data formatting** ([data.py](../ntp_python/data.py)): formatting the examples.\n",
    "2. **Tuning**  ([tune.py](../ntp_python/tune.py)): using a standard language model fine-tuning script.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Data formatting\n",
    "\n",
    "We format each (tactic-state, next-step) pair $(x_t, y_t)$ as:\n",
    "\n",
    "        [GOAL]tacticstate[PROOFSTEP]next-step<|endoftext|>\n",
    "\n",
    "Here, `[GOAL]...[PROOFSTEP]` is the input and `next-step<|endoftext|>` is the output.\n",
    "\n",
    "This format comes from [Han et al ICLR 2022]: \\\n",
    "[Proof Artifact Co-training for Theorem Proving with Language Models](https://arxiv.org/pdf/2102.06203.pdf).\n",
    "\n",
    "<!-- *Exercise:* can you think of other auxiliary tasks that might be useful? -->\n",
    "\n",
    "<!-- *Exercise:* can you think of alternative formats, e.g. which provide additional context? -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving split to disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\t169530\n",
      "val\t4053\n",
      "test\t3606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../ntp_python')\n",
    "import data\n",
    "\n",
    "datasets = data.proofstep(\n",
    "    data_dir='../data'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[GOAL]ι : Type u_1\n",
      "I✝ J✝ : Box ι\n",
      "x y : ι → ℝ\n",
      "I J : WithBot (Box ι)\n",
      "⊢ ↑I = ↑J ↔ I = J[PROOFSTEP]\n",
      "\n",
      "Output:\n",
      "simp only [Subset.antisymm_iff, ← le_antisymm_iff, withBotCoe_subset_iff]<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "example = datasets['train'][0]\n",
    "print(\"Input:\", example['input'], '', sep='\\n')\n",
    "print(\"Output:\", example['output'], sep='\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Tuning\n",
    "\n",
    "We minimally adapt a standard language-model fine-tuning script from [Stanford Alpaca](https://github.com/tatsu-lab/stanford_alpaca/blob/main/train.py). \n",
    "\n",
    "You can check out the full script at [partI_nextstep/ntp_python/tune.py](../ntp_python/tune.py). \\\n",
    "See [partI_nextstep/scripts/tune_proofstep.sh](../scripts/tune_proofstep.sh) for a command that trains on 8 GPUs with deepspeed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example command for training a 1.4b model on 1 GPU (and you can adjust the model size to be smaller to fit your compute constraints):"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "    REPO_DIR=\"..\"\n",
    "    TRAIN_FILE=${REPO_DIR}/data/leandojo_benchmark_4/processed/proofstep-train.jsonl\n",
    "    VALID_FILE=${REPO_DIR}/data/leandojo_benchmark_4/processed/proofstep-val.jsonl\n",
    "    MODEL=EleutherAI/pythia-1.4b-deduped\n",
    "\n",
    "    OUTDIR=${REPO_DIR}/model/${MODEL}\n",
    "\n",
    "    python ../ntp_python/tune.py \\\n",
    "        --model_name_or_path ${MODEL} \\\n",
    "        --train_data_path ${TRAIN_FILE} \\\n",
    "        --valid_data_path ${VALID_FILE} \\\n",
    "        --fp16 \\\n",
    "        --output_dir ${OUTDIR} \\\n",
    "        --num_train_epochs 10 \\\n",
    "        --per_device_train_batch_size 4 \\\n",
    "        --per_device_eval_batch_size 4 \\\n",
    "        --gradient_accumulation_steps 16 \\\n",
    "        --evaluation_strategy \"steps\" \\\n",
    "        --eval_steps 500 \\\n",
    "        --save_strategy \"steps\" \\\n",
    "        --save_steps 500 \\\n",
    "        --save_total_limit 1 \\\n",
    "        --learning_rate 1e-5 \\\n",
    "        --load_best_model_at_end 1 \\\n",
    "        --weight_decay 0. \\\n",
    "        --warmup_ratio 0.03 \\\n",
    "        --lr_scheduler_type \"cosine\" \\\n",
    "        --logging_steps 10 \\\n",
    "        --logging_dir \"$OUTDIR\" \\\n",
    "        --report_to=\"tensorboard\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, let's train it via real script. Since the [partI_nextstep/scripts/tune_proofstep.sh](../scripts/tune_proofstep.sh) was partly obsolete, so I amended a bit. Let's train it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct  8 06:24:31 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
      "| N/A   33C    P8              11W /  72W |    123MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA L4                      Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P8              11W /  72W |     17MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA L4                      Off | 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   33C    P8              11W /  72W |     17MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA L4                      Off | 00000000:00:06.0 Off |                    0 |\n",
      "| N/A   33C    P8              11W /  72W |     17MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA L4                      Off | 00000000:80:00.0 Off |                    0 |\n",
      "| N/A   33C    P8              11W /  72W |     17MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA L4                      Off | 00000000:80:01.0 Off |                    0 |\n",
      "| N/A   34C    P8              11W /  72W |     17MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA L4                      Off | 00000000:80:02.0 Off |                    0 |\n",
      "| N/A   34C    P8              11W /  72W |     17MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA L4                      Off | 00000000:80:03.0 Off |                    0 |\n",
      "| N/A   32C    P8              11W /  72W |     17MiB / 23034MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.6\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python version seems safe to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting accelerate==0.21.0\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting datasets==2.13.1\n",
      "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub==0.15.1\n",
      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ndjson==0.3.1\n",
      "  Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in /usr/local/lib/python3.10/dist-packages (1.5.6)\n",
      "Collecting networkx==3.1\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nh3==0.2.14\n",
      "  Downloading nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ninja==1.11.1 in /usr/local/lib/python3.10/dist-packages (1.11.1)\n",
      "Collecting numpy==1.25.0\n",
      "  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch==2.0.1\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m262.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm==4.65.0 in /usr/local/lib/python3.10/dist-packages (4.65.0)\n",
      "Collecting transformers==4.31.0\n",
      "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m196.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (23.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1) (11.0.0)\n",
      "Collecting dill<0.3.7,>=0.3.0 (from datasets==2.13.1)\n",
      "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m274.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1) (1.5.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1) (0.70.15)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.13.1) (3.8.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.15.1) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub==0.15.1) (4.7.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (1.12)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1) (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install \\\n",
    "    accelerate==0.21.0 \\\n",
    "    datasets==2.13.1 \\\n",
    "    huggingface-hub==0.15.1 \\\n",
    "    ndjson==0.3.1 \\\n",
    "    nest-asyncio==1.5.6 \\\n",
    "    networkx==3.1 \\\n",
    "    nh3==0.2.14 \\\n",
    "    ninja==1.11.1 \\\n",
    "    numpy==1.25.0 \\\n",
    "    torch==2.0.1 \\\n",
    "    tqdm==4.65.0 \\\n",
    "    transformers==4.31.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-10-08 06:30:20,854] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-10-08 06:30:32,058] [WARNING] [runner.py:203:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.\n",
      "[2023-10-08 06:30:32,058] [INFO] [runner.py:570:main] cmd = /usr/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgMywgNCwgNSwgNiwgN119 --master_addr=127.0.0.1 --master_port=29500 --enable_each_rank_log=None ../ntp_python/tune.py --deepspeed ../scripts/ds_config.json --model_name_or_path EleutherAI/pythia-2.8b-deduped --train_data_path ../data/processed/proofstep-train.jsonl --valid_data_path ../data/processed/proofstep-val.jsonl --fp16 --output_dir ../model/EleutherAI/pythia-2.8b-deduped --num_train_epochs 10 --per_device_train_batch_size 4 --per_device_eval_batch_size 4 --gradient_accumulation_steps 2 --evaluation_strategy steps --eval_steps 500 --save_strategy steps --save_steps 500 --save_total_limit 1 --learning_rate 1e-5 --load_best_model_at_end 1 --weight_decay 0. --warmup_ratio 0.03 --lr_scheduler_type cosine --logging_steps 10 --logging_dir ../model/EleutherAI/pythia-2.8b-deduped --report_to=tensorboard\n",
      "[2023-10-08 06:30:36,523] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2023-10-08 06:30:47,056] [INFO] [launch.py:138:main] 0 NCCL_VERSION=2.18.3\n",
      "[2023-10-08 06:30:47,056] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]}\n",
      "[2023-10-08 06:30:47,056] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=8, node_rank=0\n",
      "[2023-10-08 06:30:47,056] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3, 4, 5, 6, 7]})\n",
      "[2023-10-08 06:30:47,056] [INFO] [launch.py:163:main] dist_world_size=8\n",
      "[2023-10-08 06:30:47,056] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ntptutorial/partI_nextstep/notebooks/../ntp_python/tune.py\", line 7, in <module>\n",
      "    import ndjson\n",
      "ModuleNotFoundError: No module named 'ndjson'\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ntptutorial/partI_nextstep/notebooks/../ntp_python/tune.py\", line 7, in <module>\n",
      "    import ndjson\n",
      "ModuleNotFoundError: No module named 'ndjson'\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ntptutorial/partI_nextstep/notebooks/../ntp_python/tune.py\", line 7, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ntptutorial/partI_nextstep/notebooks/../ntp_python/tune.py\", line 7, in <module>\n",
      "    import ndjson\n",
      "ModuleNotFoundError: No module named 'ndjson'\n",
      "    import ndjson\n",
      "ModuleNotFoundError: No module named 'ndjson'\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ntptutorial/partI_nextstep/notebooks/../ntp_python/tune.py\", line 7, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ntptutorial/partI_nextstep/notebooks/../ntp_python/tune.py\", line 7, in <module>\n",
      "    import ndjson\n",
      "ModuleNotFoundError: No module named 'ndjson'\n",
      "    import ndjson\n",
      "ModuleNotFoundError: No module named 'ndjson'\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/ntptutorial/partI_nextstep/notebooks/../ntp_python/tune.py\", line 7, in <module>\n",
      "  File \"/workspace/ntptutorial/partI_nextstep/notebooks/../ntp_python/tune.py\", line 7, in <module>\n",
      "        import ndjsonimport ndjson\n",
      "\n",
      "ModuleNotFoundErrorModuleNotFoundError: : No module named 'ndjson'No module named 'ndjson'\n",
      "\n",
      "[2023-10-08 06:30:48,062] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 8672\n",
      "[2023-10-08 06:30:48,063] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 8673\n",
      "[2023-10-08 06:30:48,064] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 8674\n",
      "[2023-10-08 06:30:48,064] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 8675\n",
      "[2023-10-08 06:30:48,065] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 8676\n",
      "[2023-10-08 06:30:48,066] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 8677\n",
      "[2023-10-08 06:30:48,066] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 8678\n",
      "[2023-10-08 06:30:48,067] [INFO] [launch.py:315:sigkill_handler] Killing subprocess 8679\n",
      "[2023-10-08 06:30:48,068] [ERROR] [launch.py:321:sigkill_handler] ['/usr/bin/python', '-u', '../ntp_python/tune.py', '--local_rank=7', '--deepspeed', '../scripts/ds_config.json', '--model_name_or_path', 'EleutherAI/pythia-2.8b-deduped', '--train_data_path', '../data/processed/proofstep-train.jsonl', '--valid_data_path', '../data/processed/proofstep-val.jsonl', '--fp16', '--output_dir', '../model/EleutherAI/pythia-2.8b-deduped', '--num_train_epochs', '10', '--per_device_train_batch_size', '4', '--per_device_eval_batch_size', '4', '--gradient_accumulation_steps', '2', '--evaluation_strategy', 'steps', '--eval_steps', '500', '--save_strategy', 'steps', '--save_steps', '500', '--save_total_limit', '1', '--learning_rate', '1e-5', '--load_best_model_at_end', '1', '--weight_decay', '0.', '--warmup_ratio', '0.03', '--lr_scheduler_type', 'cosine', '--logging_steps', '10', '--logging_dir', '../model/EleutherAI/pythia-2.8b-deduped', '--report_to=tensorboard'] exits with return code = 1\n"
     ]
    }
   ],
   "source": [
    "!sh ../scripts/tune_proofstep.sh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After training\n",
    "\n",
    "If everything went well, you should have a model in `../model/{MODEL_NAME}/checkpoint-{BEST_STEP}`.\n",
    "\n",
    "We have fine-tuned an `EleutherAI/pythia-2.8b-deduped` model that can be accessed through HuggingFace ([link](https://huggingface.co/wellecks/llmstep-mathlib4-pythia2.8b)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "MODEL = 'wellecks/llmstep-mathlib4-pythia2.8b'\n",
    "model = transformers.GPTNeoXForCausalLM.from_pretrained(MODEL)\n",
    "tokenizer = transformers.GPTNeoXTokenizerFast.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use your own model by setting `MODEL = \"../model/{MODEL_NAME}/checkpoint-{BEST_STEP}\"` \\\n",
    "(e.g., `../model/EleutherAI/pythia-2.8b-deduped/checkpoint-5000`)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a next-step suggestion for the proof state from our original example:\n",
    "\n",
    "```lean\n",
    "    theorem test_thm (m n : Nat) (h : m.coprime n) : m.gcd n = 1\n",
    "```\n",
    "Recal from the previous notebook that the initial proof state $x_0$ is:\n",
    "\n",
    "        m n : ℕ\n",
    "        h : Nat.coprime m n\n",
    "        ⊢ Nat.gcd m n = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rw [← h.gcd_eq_one]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"[GOAL]m n : ℕ\n",
    "  h : Nat.coprime m n\n",
    "  ⊢ Nat.gcd m n = 1[PROOFSTEP]\"\"\"\n",
    "\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "out = model.generate(\n",
    "    input_ids,\n",
    "    max_new_tokens=256,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "text = tokenizer.decode(out[0][input_ids.shape[1]:], skip_special_tokens=True)\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "In the next notebook, we will prove theorems with the trained model by interacting with the Lean proof assistant.\n",
    "\n",
    "This will let us automatically check whether a generated proof (e.g., one containing the step above) is correct.\n",
    "\n",
    "Later on, we will build a VSCode plugin that returns next-step suggestions from the language model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
